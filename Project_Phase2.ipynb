{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        " Upload the Dataset\n"
      ],
      "metadata": {
        "id": "ZYw1mrYU2hWx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "GFEorZ4A2lV3",
        "outputId": "e578b8e9-4b12-43e4-8f09-e91491385af3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b5da8e00-d5b2-44e9-9158-812cf643fc7e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-b5da8e00-d5b2-44e9-9158-812cf643fc7e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving cybersecurity-ai-in-2022-2023.ipynb to cybersecurity-ai-in-2022-2023.ipynb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Load the Dataset\n"
      ],
      "metadata": {
        "id": "LIeDUCMa3BFO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Replace with your dataset path\n",
        "dataset_path = \"customer_support_chat_data.csv\"\n",
        "\n",
        "try:\n",
        "    # Load the dataset\n",
        "    df = pd.read_csv(dataset_path)\n",
        "\n",
        "    # Display the first few rows\n",
        "    print(\"Dataset loaded successfully!\\n\")\n",
        "    print(df.head())\n",
        "\n",
        "    # Show basic information\n",
        "    print(\"\\nDataset Information:\")\n",
        "    print(df.info())\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: The file at '{dataset_path}' was not found.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PnXXAfhR3EWf",
        "outputId": "3c54a579-6343-469c-abd5-24f73f40c9ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: The file at 'customer_support_chat_data.csv' was not found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Exploration\n"
      ],
      "metadata": {
        "id": "rvThlXFg3imX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Replace with the path to your dataset\n",
        "dataset_path = \"customer_support_chat_data.csv\"\n",
        "\n",
        "# Load the dataset\n",
        "try:\n",
        "    df = pd.read_csv(dataset_path)\n",
        "\n",
        "    print(\"Dataset loaded successfully!\\n\")\n",
        "    print(df.head())\n",
        "\n",
        "    # Basic info: checking for data types and missing values\n",
        "    print(\"\\nDataset Information:\")\n",
        "    print(df.info())\n",
        "\n",
        "    # Check for missing values\n",
        "    print(\"\\nMissing Values:\")\n",
        "    print(df.isnull().sum())\n",
        "\n",
        "    # Summary statistics for numerical columns\n",
        "    print(\"\\nSummary Statistics:\")\n",
        "    print(df.describe())\n",
        "\n",
        "    # Exploring the distribution of query lengths\n",
        "    df['query_length'] = df['Customer_Query'].apply(lambda x: len(str(x)))\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.histplot(df['query_length'], kde=True, bins=30, color='skyblue')\n",
        "    plt.title('Distribution of Customer Query Lengths')\n",
        "    plt.xlabel('Query Length')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.show()\n",
        "\n",
        "    # Exploring the distribution of response lengths\n",
        "    df['response_length'] = df['Bot_Response'].apply(lambda x: len(str(x)))\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.histplot(df['response_length'], kde=True, bins=30, color='lightcoral')\n",
        "    plt.title('Distribution of Bot Response Lengths')\n",
        "    plt.xlabel('Response Length')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.show()\n",
        "\n",
        "    # If you have a sentiment or intent column, you can explore the distribution of these labels:\n",
        "    if 'Sentiment' in df.columns:\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        sns.countplot(data=df, x='Sentiment', palette='viridis')\n",
        "        plt.title('Distribution of Sentiment in Bot Responses')\n",
        "        plt.xlabel('Sentiment')\n",
        "        plt.ylabel('Frequency')\n",
        "        plt.show()\n",
        "\n",
        "    # You can also visualize the most frequent customer queries (Word Cloud or Top Queries)\n",
        "    from collections import Counter\n",
        "    from wordcloud import WordCloud\n",
        "\n",
        "    # Combine all customer queries into one string\n",
        "    all_queries = ' '.join(df['Customer_Query'].dropna().astype(str))\n",
        "\n",
        "    # Generate a WordCloud for most common words\n",
        "    wordcloud = WordCloud(width=800, height=400, background_color='white').generate(all_queries)\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.imshow(wordcloud, interpolation='bilinear')\n",
        "    plt.axis('off')\n",
        "    plt.title('Most Frequent Words in Customer Queries')\n",
        "    plt.show()\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: The file at '{dataset_path}' was not found.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YJ9f6lc4MEm",
        "outputId": "2e1ff477-b38c-4bb7-a32e-a4643937819b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: The file at 'customer_support_chat_data.csv' was not found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check for Missing Values and Duplicates\n"
      ],
      "metadata": {
        "id": "lvfFvf2F4a-i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Replace with the path to your dataset\n",
        "dataset_path = \"customer_support_chat_data.csv\"\n",
        "\n",
        "# Load the dataset\n",
        "try:\n",
        "    df = pd.read_csv(dataset_path)\n",
        "\n",
        "    print(\"Dataset loaded successfully!\\n\")\n",
        "\n",
        "    # Check for missing values\n",
        "    print(\"\\nChecking for missing values...\\n\")\n",
        "    missing_values = df.isnull().sum()\n",
        "    print(missing_values[missing_values > 0])  # Display only columns with missing values\n",
        "\n",
        "    # Check for duplicate rows\n",
        "    print(\"\\nChecking for duplicate rows...\\n\")\n",
        "    duplicate_rows = df.duplicated().sum()  # Count duplicate rows\n",
        "    print(f\"Number of duplicate rows: {duplicate_rows}\")\n",
        "\n",
        "    # If duplicates exist, show the first few duplicates\n",
        "    if duplicate_rows > 0:\n",
        "        print(\"\\nFirst few duplicate rows:\")\n",
        "        print(df[df.duplicated()].head())\n",
        "\n",
        "    # Handle missing values (you can either drop or fill them)\n",
        "    # Example 1: Drop rows with missing values\n",
        "    df_no_missing = df.dropna()\n",
        "    print(f\"\\nDataset size after dropping missing values: {df_no_missing.shape}\")\n",
        "\n",
        "    # Example 2: Fill missing values with a default value (like 'unknown' or mean/median)\n",
        "    df_filled = df.fillna({\"Customer_Query\": \"Unknown\", \"Bot_Response\": \"No Response\"})\n",
        "    print(\"\\nMissing values have been filled.\\n\")\n",
        "\n",
        "    # Show the cleaned dataset (after handling missing values)\n",
        "    print(\"\\nCleaned Dataset after Handling Missing Values:\")\n",
        "    print(df_filled.head())\n",
        "\n",
        "    # Handling duplicates: You can drop duplicates\n",
        "    df_no_duplicates = df.drop_duplicates()\n",
        "    print(f\"\\nDataset size after dropping duplicates: {df_no_duplicates.shape}\")\n",
        "\n",
        "    # Show the cleaned dataset (after handling duplicates)\n",
        "    print(\"\\nCleaned Dataset after Removing Duplicates:\")\n",
        "    print(df_no_duplicates.head())\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: The file at '{dataset_path}' was not found.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--KgXEDQ4f3G",
        "outputId": "2aca76ae-282b-4cd6-9bd9-e7477b6618cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: The file at 'customer_support_chat_data.csv' was not found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualize a Few Features\n"
      ],
      "metadata": {
        "id": "Wb3OaVmW5QH_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from wordcloud import WordCloud\n",
        "from collections import Counter\n",
        "\n",
        "# Replace with the path to your dataset\n",
        "dataset_path = \"customer_support_chat_data.csv\"\n",
        "\n",
        "# Load the dataset\n",
        "try:\n",
        "    df = pd.read_csv(dataset_path)\n",
        "\n",
        "    # Ensure the data is loaded correctly\n",
        "    print(\"Dataset loaded successfully!\\n\")\n",
        "    print(df.head())\n",
        "\n",
        "    # 1. Query Length vs Bot Response Length\n",
        "    df['query_length'] = df['Customer_Query'].apply(lambda x: len(str(x)))\n",
        "    df['response_length'] = df['Bot_Response'].apply(lambda x: len(str(x)))\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.scatterplot(x='query_length', y='response_length', data=df, color='skyblue')\n",
        "    plt.title('Customer Query Length vs Bot Response Length')\n",
        "    plt.xlabel('Customer Query Length')\n",
        "    plt.ylabel('Bot Response Length')\n",
        "    plt.show()\n",
        "\n",
        "    # 2. Distribution of Query Lengths (Histogram)\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.histplot(df['query_length'], kde=True, bins=30, color='lightcoral')\n",
        "    plt.title('Distribution of Customer Query Lengths')\n",
        "    plt.xlabel('Query Length')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.show()\n",
        "\n",
        "    # 3. Distribution of Response Lengths (Histogram)\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.histplot(df['response_length'], kde=True, bins=30, color='lightgreen')\n",
        "    plt.title('Distribution of Bot Response Lengths')\n",
        "    plt.xlabel('Response Length')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.show()\n",
        "\n",
        "    # 4. Most Frequent Words in Customer Queries (Word Cloud)\n",
        "    all_queries = ' '.join(df['Customer_Query'].dropna().astype(str))\n",
        "    wordcloud = WordCloud(width=800, height=400, background_color='white').generate(all_queries)\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.imshow(wordcloud, interpolation='bilinear')\n",
        "    plt.axis('off')\n",
        "    plt.title('Most Frequent Words in Customer Queries')\n",
        "    plt.show()\n",
        "\n",
        "    # 5. Distribution of Sentiment (If Sentiment Column Exists)\n",
        "    if 'Sentiment' in df.columns:\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        sns.countplot(data=df, x='Sentiment', palette='viridis')\n",
        "        plt.title('Distribution of Sentiment in Customer Queries')\n",
        "        plt.xlabel('Sentiment')\n",
        "        plt.ylabel('Frequency')\n",
        "        plt.show()\n",
        "\n",
        "    # 6. Distribution of Bot Response Categories (If Intent Exists)\n",
        "    if 'Intent' in df.columns:\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        sns.countplot(data=df, x='Intent', palette='magma')\n",
        "        plt.title('Distribution of Bot Response Intents')\n",
        "        plt.xlabel('Intent')\n",
        "        plt.ylabel('Frequency')\n",
        "        plt.xticks(rotation=45)\n",
        "        plt.show()\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: The file at '{dataset_path}' was not found.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwRWSQkz5U7P",
        "outputId": "e3dcd713-b61a-4120-fad3-1d5e3a5b13c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: The file at 'customer_support_chat_data.csv' was not found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Identify Target and Features\n"
      ],
      "metadata": {
        "id": "hWjMdC7a5xh3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy import displacy\n",
        "import re\n",
        "\n",
        "# Load the large English model from spaCy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Example text: \"Revolutionizing Customer Support with an Intelligent Chatbot\"\n",
        "text = \"\"\"\n",
        "Revolutionizing Customer Support with an Intelligent Chatbot\n",
        "\n",
        "In today's fast-paced world, businesses must provide quick and efficient customer support. Traditional support channels like phone calls and emails are becoming outdated, and customers expect faster responses.\n",
        "\n",
        "An intelligent chatbot powered by artificial intelligence (AI) offers a solution. These chatbots are capable of understanding customer queries, offering real-time solutions, and providing 24/7 support. They can be integrated into websites, mobile apps, and social media platforms.\n",
        "\n",
        "The main features of an intelligent chatbot include natural language processing (NLP) for understanding customer queries, machine learning for continuous improvement, and data-driven insights for personalized customer service.\n",
        "\n",
        "Target Audience:\n",
        "1. Businesses of all sizes looking to automate customer support.\n",
        "2. Customers who prefer fast, self-service support options.\n",
        "3. Support agents who benefit from AI-driven tools for handling more complex cases.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Process the text through the NLP pipeline\n",
        "doc = nlp(text)\n",
        "\n",
        "# Function to extract targets (audience)\n",
        "def extract_target(doc):\n",
        "    targets = []\n",
        "    for sent in doc.sents:\n",
        "        if \"target\" in sent.text.lower() or \"audience\" in sent.text.lower():\n",
        "            targets.append(sent.text)\n",
        "    return targets\n",
        "\n",
        "# Function to extract features of the chatbot\n",
        "def extract_features(doc):\n",
        "    features = []\n",
        "    for sent in doc.sents:\n",
        "        if \"feature\" in sent.text.lower() or \"capability\" in sent.text.lower() or \"functionality\" in sent.text.lower():\n",
        "            features.append(sent.text)\n",
        "    return features\n",
        "\n",
        "# Function to identify key phrases related to the chatbot and customer support\n",
        "def extract_keywords(doc):\n",
        "    keywords = []\n",
        "    for token in doc:\n",
        "        if token.pos_ in [\"NOUN\", \"ADJ\", \"PROPN\"]:\n",
        "            keywords.append(token.text.lower())\n",
        "    return list(set(keywords))\n",
        "\n",
        "# Extracting information\n",
        "target = extract_target(doc)\n",
        "features = extract_features(doc)\n",
        "keywords = extract_keywords(doc)\n",
        "\n",
        "# Output the results\n",
        "print(\"Targets Identified:\")\n",
        "for t in target:\n",
        "    print(t)\n",
        "\n",
        "print(\"\\nFeatures Identified:\")\n",
        "for f in features:\n",
        "    print(f)\n",
        "\n",
        "print(\"\\nKeywords Identified:\")\n",
        "print(keywords)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "StMKwwSe63o_",
        "outputId": "30855b18-97d1-4024-e5ed-7382368bd0a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Targets Identified:\n",
            "Target Audience:\n",
            "1.\n",
            "\n",
            "Features Identified:\n",
            "The main features of an intelligent chatbot include natural language processing (NLP) for understanding customer queries, machine learning for continuous improvement, and data-driven insights for personalized customer service.\n",
            "\n",
            "\n",
            "\n",
            "Keywords Identified:\n",
            "['world', 'features', 'self', 'options', 'tools', 'improvement', 'capable', 'platforms', 'responses', 'social', 'solution', 'media', 'language', 'cases', 'artificial', 'intelligent', 'time', 'nlp', 'intelligence', 'service', 'processing', 'emails', 'calls', 'insights', 'revolutionizing', 'real', 'agents', 'solutions', 'customer', 'main', 'learning', 'queries', 'audience', 'support', 'phone', 'customers', 'complex', 'faster', 'quick', 'websites', 'personalized', 'machine', 'continuous', 'channels', 'efficient', 'ai', 'chatbots', 'target', 'today', 'data', 'chatbot', 'traditional', 'mobile', 'natural', 'apps', 'businesses', 'sizes']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert Categorical Columns to Numerical\n"
      ],
      "metadata": {
        "id": "NI5h6XQn69kG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Sample dataset\n",
        "data = {\n",
        "    'User ID': [1, 2, 3, 4],\n",
        "    'Customer\\'s Issue Type': ['Technical Issue', 'Billing Issue', 'Technical Issue', 'Account Issue'],\n",
        "    'Chatbot Model': ['AI-Chatbot', 'Rule-Based', 'AI-Chatbot', 'Hybrid'],\n",
        "    'User Satisfaction': ['High', 'Low', 'Medium', 'High']\n",
        "}\n",
        "\n",
        "# Create DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Initialize LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Convert 'Customer\\'s Issue Type' using Label Encoding\n",
        "df['Customer\\'s Issue Type'] = label_encoder.fit_transform(df['Customer\\'s Issue Type'])\n",
        "\n",
        "# Convert 'Chatbot Model' using Label Encoding\n",
        "df['Chatbot Model'] = label_encoder.fit_transform(df['Chatbot Model'])\n",
        "\n",
        "# Convert 'User Satisfaction' using Label Encoding\n",
        "df['User Satisfaction'] = label_encoder.fit_transform(df['User Satisfaction'])\n",
        "\n",
        "# Display the result\n",
        "print(\"Converted Dataset:\")\n",
        "print(df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mbV97ANI7D7e",
        "outputId": "54d0050b-5da5-4a84-b20d-cb2ebcee2c53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converted Dataset:\n",
            "   User ID  Customer's Issue Type  Chatbot Model  User Satisfaction\n",
            "0        1                      2              0                  0\n",
            "1        2                      1              2                  1\n",
            "2        3                      2              0                  2\n",
            "3        4                      0              1                  0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "One-Hot Encoding\n"
      ],
      "metadata": {
        "id": "pwMW0fe37pSW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Sample dataset\n",
        "data = {\n",
        "    'User ID': [1, 2, 3, 4],\n",
        "    'Customer\\'s Issue Type': ['Technical Issue', 'Billing Issue', 'Technical Issue', 'Account Issue'],\n",
        "    'Chatbot Model': ['AI-Chatbot', 'Rule-Based', 'AI-Chatbot', 'Hybrid'],\n",
        "    'User Satisfaction': ['High', 'Low', 'Medium', 'High']\n",
        "}\n",
        "\n",
        "# Create DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Apply One-Hot Encoding to categorical columns\n",
        "df_one_hot = pd.get_dummies(df, columns=['Customer\\'s Issue Type', 'Chatbot Model', 'User Satisfaction'])\n",
        "\n",
        "# Display the result\n",
        "print(\"One-Hot Encoded Dataset:\")\n",
        "print(df_one_hot)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uVnQRRbi7tZv",
        "outputId": "22661415-2555-43d7-8b50-d26ff7353410"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "One-Hot Encoded Dataset:\n",
            "   User ID  Customer's Issue Type_Account Issue  \\\n",
            "0        1                                False   \n",
            "1        2                                False   \n",
            "2        3                                False   \n",
            "3        4                                 True   \n",
            "\n",
            "   Customer's Issue Type_Billing Issue  Customer's Issue Type_Technical Issue  \\\n",
            "0                                False                                   True   \n",
            "1                                 True                                  False   \n",
            "2                                False                                   True   \n",
            "3                                False                                  False   \n",
            "\n",
            "   Chatbot Model_AI-Chatbot  Chatbot Model_Hybrid  Chatbot Model_Rule-Based  \\\n",
            "0                      True                 False                     False   \n",
            "1                     False                 False                      True   \n",
            "2                      True                 False                     False   \n",
            "3                     False                  True                     False   \n",
            "\n",
            "   User Satisfaction_High  User Satisfaction_Low  User Satisfaction_Medium  \n",
            "0                    True                  False                     False  \n",
            "1                   False                   True                     False  \n",
            "2                   False                  False                      True  \n",
            "3                    True                  False                     False  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature Scaling\n"
      ],
      "metadata": {
        "id": "u7A45YO-8Ef-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "\n",
        "# Sample dataset\n",
        "data = {\n",
        "    'User ID': [1, 2, 3, 4],\n",
        "    'Response Time (sec)': [34, 120, 60, 90],\n",
        "    'Customer Satisfaction Score': [7, 8, 5, 9],\n",
        "    'Chatbot Interactions': [15, 45, 30, 60]\n",
        "}\n",
        "\n",
        "# Create DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Extract numerical features to scale\n",
        "numerical_features = ['Response Time (sec)', 'Customer Satisfaction Score', 'Chatbot Interactions']\n",
        "\n",
        "# Min-Max Scaling\n",
        "min_max_scaler = MinMaxScaler()\n",
        "df_min_max_scaled = df.copy()  # Copy the original data to avoid modifying it directly\n",
        "df_min_max_scaled[numerical_features] = min_max_scaler.fit_transform(df[numerical_features])\n",
        "\n",
        "# Standardization (Z-score Scaling)\n",
        "standard_scaler = StandardScaler()\n",
        "df_standard_scaled = df.copy()  # Copy the original data to avoid modifying it directly\n",
        "df_standard_scaled[numerical_features] = standard_scaler.fit_transform(df[numerical_features])\n",
        "\n",
        "# Display the results\n",
        "print(\"Original Dataset:\")\n",
        "print(df)\n",
        "\n",
        "print(\"\\nMin-Max Scaled Dataset:\")\n",
        "print(df_min_max_scaled)\n",
        "\n",
        "print(\"\\nStandardized Dataset (Z-score):\")\n",
        "print(df_standard_scaled)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8uEJx8jI8Ij-",
        "outputId": "85531e2c-cffa-4dde-d874-4e4c5a75658a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Dataset:\n",
            "   User ID  Response Time (sec)  Customer Satisfaction Score  \\\n",
            "0        1                   34                            7   \n",
            "1        2                  120                            8   \n",
            "2        3                   60                            5   \n",
            "3        4                   90                            9   \n",
            "\n",
            "   Chatbot Interactions  \n",
            "0                    15  \n",
            "1                    45  \n",
            "2                    30  \n",
            "3                    60  \n",
            "\n",
            "Min-Max Scaled Dataset:\n",
            "   User ID  Response Time (sec)  Customer Satisfaction Score  \\\n",
            "0        1             0.000000                         0.50   \n",
            "1        2             1.000000                         0.75   \n",
            "2        3             0.302326                         0.00   \n",
            "3        4             0.651163                         1.00   \n",
            "\n",
            "   Chatbot Interactions  \n",
            "0              0.000000  \n",
            "1              0.666667  \n",
            "2              0.333333  \n",
            "3              1.000000  \n",
            "\n",
            "Standardized Dataset (Z-score):\n",
            "   User ID  Response Time (sec)  Customer Satisfaction Score  \\\n",
            "0        1            -1.303619                    -0.169031   \n",
            "1        2             1.365696                     0.507093   \n",
            "2        3            -0.496617                    -1.521278   \n",
            "3        4             0.434540                     1.183216   \n",
            "\n",
            "   Chatbot Interactions  \n",
            "0             -1.341641  \n",
            "1              0.447214  \n",
            "2             -0.447214  \n",
            "3              1.341641  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train-Test Split\n"
      ],
      "metadata": {
        "id": "OsZ3YE2V88lf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Sample dataset\n",
        "data = {\n",
        "    'Response Time (sec)': [34, 120, 60, 90, 45, 30, 100, 70],\n",
        "    'Customer Satisfaction Score': [7, 8, 5, 9, 6, 7, 8, 6],\n",
        "    'Chatbot Interactions': [15, 45, 30, 60, 50, 20, 80, 55],\n",
        "    'Customer Satisfaction (Target)': [1, 0, 0, 1, 1, 0, 1, 1]  # 1 = Satisfied, 0 = Not Satisfied\n",
        "}\n",
        "\n",
        "# Create DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Features (X) and Target (y)\n",
        "X = df[['Response Time (sec)', 'Customer Satisfaction Score', 'Chatbot Interactions']]\n",
        "y = df['Customer Satisfaction (Target)']\n",
        "\n",
        "# Perform Train-Test Split (80% Train, 20% Test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Display the results\n",
        "print(\"Training Data (X_train):\")\n",
        "print(X_train)\n",
        "\n",
        "print(\"\\nTest Data (X_test):\")\n",
        "print(X_test)\n",
        "\n",
        "print(\"\\nTraining Labels (y_train):\")\n",
        "print(y_train)\n",
        "\n",
        "print(\"\\nTest Labels (y_test):\")\n",
        "print(y_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BjNDVJWu89xB",
        "outputId": "63d871df-d944-426e-cac5-2f6d6c3b9a99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Data (X_train):\n",
            "   Response Time (sec)  Customer Satisfaction Score  Chatbot Interactions\n",
            "0                   34                            7                    15\n",
            "7                   70                            6                    55\n",
            "2                   60                            5                    30\n",
            "4                   45                            6                    50\n",
            "3                   90                            9                    60\n",
            "6                  100                            8                    80\n",
            "\n",
            "Test Data (X_test):\n",
            "   Response Time (sec)  Customer Satisfaction Score  Chatbot Interactions\n",
            "1                  120                            8                    45\n",
            "5                   30                            7                    20\n",
            "\n",
            "Training Labels (y_train):\n",
            "0    1\n",
            "7    1\n",
            "2    0\n",
            "4    1\n",
            "3    1\n",
            "6    1\n",
            "Name: Customer Satisfaction (Target), dtype: int64\n",
            "\n",
            "Test Labels (y_test):\n",
            "1    0\n",
            "5    0\n",
            "Name: Customer Satisfaction (Target), dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Building\n"
      ],
      "metadata": {
        "id": "toN9NQq-9IFO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Sample dataset\n",
        "data = {\n",
        "    'Response Time (sec)': [34, 120, 60, 90, 45, 30, 100, 70],\n",
        "    'Customer Satisfaction Score': [7, 8, 5, 9, 6, 7, 8, 6],\n",
        "    'Chatbot Interactions': [15, 45, 30, 60, 50, 20, 80, 55],\n",
        "    'Customer Satisfaction (Target)': [1, 0, 0, 1, 1, 0, 1, 1]  # 1 = Satisfied, 0 = Not Satisfied\n",
        "}\n",
        "\n",
        "# Create DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Features (X) and Target (y)\n",
        "X = df[['Response Time (sec)', 'Customer Satisfaction Score', 'Chatbot Interactions']]\n",
        "y = df['Customer Satisfaction (Target)']\n",
        "\n",
        "# Train-Test Split (80% Train, 20% Test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Feature Scaling (Standardization)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Initialize Logistic Regression Model\n",
        "model = LogisticRegression()\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXvr4b5j9Os1",
        "outputId": "03f76f5c-e2fa-4615-87dc-a416d26e7046"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.00%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       2.0\n",
            "           1       0.00      0.00      0.00       0.0\n",
            "\n",
            "    accuracy                           0.00       2.0\n",
            "   macro avg       0.00      0.00      0.00       2.0\n",
            "weighted avg       0.00      0.00      0.00       2.0\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[0 2]\n",
            " [0 0]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluation\n"
      ],
      "metadata": {
        "id": "1Q99equu9g32"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Sample dataset\n",
        "data = {\n",
        "    'Response Time (sec)': [34, 120, 60, 90, 45, 30, 100, 70],\n",
        "    'Customer Satisfaction Score': [7, 8, 5, 9, 6, 7, 8, 6],\n",
        "    'Chatbot Interactions': [15, 45, 30, 60, 50, 20, 80, 55],\n",
        "    'Customer Satisfaction (Target)': [1, 0, 0, 1, 1, 0, 1, 1]  # 1 = Satisfied, 0 = Not Satisfied\n",
        "}\n",
        "\n",
        "# Create DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Features (X) and Target (y)\n",
        "X = df[['Response Time (sec)', 'Customer Satisfaction Score', 'Chatbot Interactions']]\n",
        "y = df['Customer Satisfaction (Target)']\n",
        "\n",
        "# Train-Test Split (80% Train, 20% Test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Feature Scaling (Standardization)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Initialize Logistic Regression Model\n",
        "model = LogisticRegression()\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "# Evaluate the model\n",
        "\n",
        "# 1. Accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# 2. Classification Report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# 3. Confusion Matrix\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "# Optionally, display metrics individually\n",
        "print(\"\\nPrecision, Recall, and F1-Score for Class 1 (Satisfied):\")\n",
        "print(f\"Precision: {classification_report(y_test, y_pred, output_dict=True)['1']['precision']}\")\n",
        "print(f\"Recall: {classification_report(y_test, y_pred, output_dict=True)['1']['recall']}\")\n",
        "print(f\"F1-Score: {classification_report(y_test, y_pred, output_dict=True)['1']['f1-score']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCtbQefe9nSe",
        "outputId": "0e296e10-a468-4484-a2ea-64367acb9891"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.00%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       2.0\n",
            "           1       0.00      0.00      0.00       0.0\n",
            "\n",
            "    accuracy                           0.00       2.0\n",
            "   macro avg       0.00      0.00      0.00       2.0\n",
            "weighted avg       0.00      0.00      0.00       2.0\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[0 2]\n",
            " [0 0]]\n",
            "\n",
            "Precision, Recall, and F1-Score for Class 1 (Satisfied):\n",
            "Precision: 0.0\n",
            "Recall: 0.0\n",
            "F1-Score: 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make Predictions from New Input"
      ],
      "metadata": {
        "id": "MDNnvm9K-NXX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Sample dataset (same as before)\n",
        "data = {\n",
        "    'Response Time (sec)': [34, 120, 60, 90, 45, 30, 100, 70],\n",
        "    'Customer Satisfaction Score': [7, 8, 5, 9, 6, 7, 8, 6],\n",
        "    'Chatbot Interactions': [15, 45, 30, 60, 50, 20, 80, 55],\n",
        "    'Customer Satisfaction (Target)': [1, 0, 0, 1, 1, 0, 1, 1]  # 1 = Satisfied, 0 = Not Satisfied\n",
        "}\n",
        "\n",
        "# Create DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Features (X) and Target (y)\n",
        "X = df[['Response Time (sec)', 'Customer Satisfaction Score', 'Chatbot Interactions']]\n",
        "y = df['Customer Satisfaction (Target)']\n",
        "\n",
        "# Train-Test Split (80% Train, 20% Test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Feature Scaling (Standardization)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Initialize and Train Logistic Regression Model\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# New input data (new customer)\n",
        "new_data = {\n",
        "    'Response Time (sec)': [50],  # Example value for new customer\n",
        "    'Customer Satisfaction Score': [7],  # Example value\n",
        "    'Chatbot Interactions': [40]  # Example value\n",
        "}\n",
        "\n",
        "# Create DataFrame for the new input\n",
        "new_input = pd.DataFrame(new_data)\n",
        "\n",
        "# Apply the same scaling to the new input data\n",
        "new_input_scaled = scaler.transform(new_input)\n",
        "\n",
        "# Make prediction with the trained model\n",
        "prediction = model.predict(new_input_scaled)\n",
        "\n",
        "# Output the prediction\n",
        "if prediction[0] == 1:\n",
        "    print(\"Prediction: Customer is Satisfied\")\n",
        "else:\n",
        "    print(\"Prediction: Customer is Not Satisfied\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KHSBQsK_-ft1",
        "outputId": "2f7c86d2-1a0e-4fda-99a9-5eb9ffe05d06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: Customer is Satisfied\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert to DataFrame and Encode"
      ],
      "metadata": {
        "id": "GGMVSTMP-kAP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Sample raw data (you may get this data from CSV, database, etc.)\n",
        "data = {\n",
        "    'Customer Type': ['New', 'Returning', 'New', 'Returning', 'New'],\n",
        "    'Satisfaction Level': ['High', 'Low', 'Medium', 'High', 'Medium'],\n",
        "    'Response Time (sec)': [34, 120, 60, 90, 45],\n",
        "    'Customer Satisfaction (Target)': [1, 0, 0, 1, 1]  # 1 = Satisfied, 0 = Not Satisfied\n",
        "}\n",
        "\n",
        "# Convert to DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Display the original DataFrame\n",
        "print(\"Original DataFrame:\")\n",
        "print(df)\n",
        "\n",
        "# Encode categorical variables (Customer Type and Satisfaction Level)\n",
        "# 1. Using LabelEncoder for \"Customer Type\" and \"Satisfaction Level\"\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Encode \"Customer Type\"\n",
        "df['Customer Type Encoded'] = label_encoder.fit_transform(df['Customer Type'])\n",
        "\n",
        "# Encode \"Satisfaction Level\"\n",
        "df['Satisfaction Level Encoded'] = label_encoder.fit_transform(df['Satisfaction Level'])\n",
        "\n",
        "# 2. Using OneHotEncoder (for illustration, we will use OneHotEncoding on \"Satisfaction Level\")\n",
        "# OneHotEncoder will create separate columns for each category in the \"Satisfaction Level\"\n",
        "column_transformer = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('encoder', OneHotEncoder(), ['Satisfaction Level'])\n",
        "    ],\n",
        "    remainder='passthrough'  # Keep other columns as they are\n",
        ")\n",
        "\n",
        "# Apply OneHotEncoder transformation\n",
        "transformed_data = column_transformer.fit_transform(df)\n",
        "\n",
        "# Get feature names after OneHotEncoding\n",
        "feature_names = column_transformer.get_feature_names_out(df.columns)\n",
        "\n",
        "# Create DataFrame with correct column names\n",
        "df_encoded = pd.DataFrame(transformed_data, columns=feature_names)\n",
        "\n",
        "# Display the final DataFrame with encoded features\n",
        "print(\"\\nDataFrame with Encoded Features:\")\n",
        "print(df_encoded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eij4zhhZ_PZ3",
        "outputId": "b6035228-c5a4-4c6e-e5fa-08ad990b2074"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original DataFrame:\n",
            "  Customer Type Satisfaction Level  Response Time (sec)  \\\n",
            "0           New               High                   34   \n",
            "1     Returning                Low                  120   \n",
            "2           New             Medium                   60   \n",
            "3     Returning               High                   90   \n",
            "4           New             Medium                   45   \n",
            "\n",
            "   Customer Satisfaction (Target)  \n",
            "0                               1  \n",
            "1                               0  \n",
            "2                               0  \n",
            "3                               1  \n",
            "4                               1  \n",
            "\n",
            "DataFrame with Encoded Features:\n",
            "  encoder__Satisfaction Level_High encoder__Satisfaction Level_Low  \\\n",
            "0                              1.0                             0.0   \n",
            "1                              0.0                             1.0   \n",
            "2                              0.0                             0.0   \n",
            "3                              1.0                             0.0   \n",
            "4                              0.0                             0.0   \n",
            "\n",
            "  encoder__Satisfaction Level_Medium remainder__Customer Type  \\\n",
            "0                                0.0                      New   \n",
            "1                                0.0                Returning   \n",
            "2                                1.0                      New   \n",
            "3                                0.0                Returning   \n",
            "4                                1.0                      New   \n",
            "\n",
            "  remainder__Response Time (sec) remainder__Customer Satisfaction (Target)  \\\n",
            "0                             34                                         1   \n",
            "1                            120                                         0   \n",
            "2                             60                                         0   \n",
            "3                             90                                         1   \n",
            "4                             45                                         1   \n",
            "\n",
            "  remainder__Customer Type Encoded remainder__Satisfaction Level Encoded  \n",
            "0                                0                                     0  \n",
            "1                                1                                     1  \n",
            "2                                0                                     2  \n",
            "3                                1                                     0  \n",
            "4                                0                                     2  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predict the Final Grade"
      ],
      "metadata": {
        "id": "XAAG5HfK_WPu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Sample dataset: customer interactions data\n",
        "data = {\n",
        "    'Response Time (sec)': [34, 120, 60, 90, 45, 30, 100, 70],\n",
        "    'Customer Satisfaction Score': [7, 8, 5, 9, 6, 7, 8, 6],\n",
        "    'Chatbot Interactions': [15, 45, 30, 60, 50, 20, 80, 55],\n",
        "    'Final Grade': [85, 60, 70, 95, 80, 72, 90, 75]  # Target: Final Grade (score)\n",
        "}\n",
        "\n",
        "# Convert to DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Features (X) and Target (y)\n",
        "X = df[['Response Time (sec)', 'Customer Satisfaction Score', 'Chatbot Interactions']]\n",
        "y = df['Final Grade']\n",
        "\n",
        "# Train-Test Split (80% Train, 20% Test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Feature Scaling (Standardization)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Initialize Linear Regression Model\n",
        "model = LinearRegression()\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "# Evaluate the model\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "print(f\"R-squared: {r2}\")\n",
        "\n",
        "# Example of making predictions on new data\n",
        "new_data = {\n",
        "    'Response Time (sec)': [50],\n",
        "    'Customer Satisfaction Score': [7],\n",
        "    'Chatbot Interactions': [40]\n",
        "}\n",
        "\n",
        "# Convert new input into DataFrame\n",
        "new_input = pd.DataFrame(new_data)\n",
        "\n",
        "# Scale the new input data using the same scaler\n",
        "new_input_scaled = scaler.transform(new_input)\n",
        "\n",
        "# Make prediction for new data\n",
        "predicted_grade = model.predict(new_input_scaled)\n",
        "\n",
        "print(f\"\\nPredicted Final Grade for new customer: {predicted_grade[0]:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rItd4cdj_e_F",
        "outputId": "71457e9b-bbdd-45b9-d60e-64ee8b613f5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 378.2096309538612\n",
            "R-squared: -9.5058230820517\n",
            "\n",
            "Predicted Final Grade for new customer: 84.98\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deployment-Building an Interactive App"
      ],
      "metadata": {
        "id": "V3tHmSkZAGFv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Sample dataset for training the model\n",
        "data = {\n",
        "    'Response Time (sec)': [34, 120, 60, 90, 45, 30, 100, 70],\n",
        "    'Customer Satisfaction Score': [7, 8, 5, 9, 6, 7, 8, 6],\n",
        "    'Chatbot Interactions': [15, 45, 30, 60, 50, 20, 80, 55],\n",
        "    'Final Grade': [85, 60, 70, 95, 80, 72, 90, 75]  # Target: Final Grade (score)\n",
        "}\n",
        "\n",
        "# Convert data to DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Features (X) and Target (y)\n",
        "X = df[['Response Time (sec)', 'Customer Satisfaction Score', 'Chatbot Interactions']]\n",
        "y = df['Final Grade']\n",
        "\n",
        "# Train-Test Split (80% Train, 20% Test)\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Feature Scaling (Standardization)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train a Linear Regression Model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Streamlit App\n",
        "def app():\n",
        "    st.title(\"Customer Satisfaction and Final Grade Prediction\")\n",
        "\n",
        "    # User input for features\n",
        "    response_time = st.number_input(\"Response Time (sec)\", min_value=0, max_value=300, value=50)\n",
        "    satisfaction_score = st.slider(\"Customer Satisfaction Score\", min_value=1, max_value=10, value=7)\n",
        "    chatbot_interactions = st.number_input(\"Chatbot Interactions\", min_value=1, max_value=100, value=30)\n",
        "\n",
        "    # Prepare the input data\n",
        "    input_data = pd.DataFrame({\n",
        "        'Response Time (sec)': [response_time],\n",
        "        'Customer Satisfaction Score': [satisfaction_score],\n",
        "        'Chatbot Interactions': [chatbot_interactions]\n",
        "    })\n",
        "\n",
        "    # Scale the input data\n",
        "    input_scaled = scaler.transform(input_data)\n",
        "\n",
        "    # Make prediction when the user clicks the button\n",
        "    if st.button('Predict Final Grade'):\n",
        "        predicted_grade = model.predict(input_scaled)\n",
        "        st.write(f\"Predicted Final Grade: {predicted_grade[0]:.2f}\")\n",
        "\n",
        "    # Optionally show the original data for reference\n",
        "    if st.checkbox(\"Show Training Data\"):\n",
        "        st.write(df)\n",
        "\n",
        "# Run the Streamlit app\n",
        "if __name__ == \"__main__\":\n",
        "    app()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EBLbJk_yBL2w",
        "outputId": "0e1aca85-2ec5-4049-f718-f5dced420833"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-05-07 09:13:31.477 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-05-07 09:13:31.884 \n",
            "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
            "  command:\n",
            "\n",
            "    streamlit run /usr/local/lib/python3.11/dist-packages/colab_kernel_launcher.py [ARGUMENTS]\n",
            "2025-05-07 09:13:31.895 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-05-07 09:13:31.896 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-05-07 09:13:31.898 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-05-07 09:13:31.899 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-05-07 09:13:31.901 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-05-07 09:13:31.903 Session state does not function when running a script without `streamlit run`\n",
            "2025-05-07 09:13:31.905 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-05-07 09:13:31.906 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-05-07 09:13:31.909 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-05-07 09:13:31.910 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-05-07 09:13:31.912 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-05-07 09:13:31.913 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-05-07 09:13:31.917 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-05-07 09:13:31.918 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-05-07 09:13:31.920 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-05-07 09:13:31.921 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-05-07 09:13:31.924 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-05-07 09:13:31.925 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-05-07 09:13:31.951 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-05-07 09:13:31.956 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-05-07 09:13:31.960 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-05-07 09:13:31.961 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-05-07 09:13:31.965 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-05-07 09:13:31.966 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-05-07 09:13:31.971 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-05-07 09:13:31.972 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-05-07 09:13:31.974 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-05-07 09:13:31.976 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-05-07 09:13:31.981 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        }
      ]
    },
    {
      "source": [
        "!pip install streamlit"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fs-A4Z_uBXd7",
        "outputId": "60b06716-1649-4530-8c1a-44ca0df55ef3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.45.0-py3-none-any.whl.metadata (8.9 kB)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.1.8)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.2.1)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.4)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.13.2)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.37.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.4.26)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.24.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Downloading streamlit-1.45.0-py3-none-any.whl (9.9 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m65.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m71.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: watchdog, pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 streamlit-1.45.0 watchdog-6.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a Predition Function"
      ],
      "metadata": {
        "id": "BQFrek9QCjGn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Sample dataset: customer interactions data\n",
        "data = {\n",
        "    'Response Time (sec)': [34, 120, 60, 90, 45, 30, 100, 70],\n",
        "    'Customer Satisfaction Score': [7, 8, 5, 9, 6, 7, 8, 6],\n",
        "    'Chatbot Interactions': [15, 45, 30, 60, 50, 20, 80, 55],\n",
        "    'Final Grade': [85, 60, 70, 95, 80, 72, 90, 75]  # Target: Final Grade (score)\n",
        "}\n",
        "\n",
        "# Convert to DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Features (X) and Target (y)\n",
        "X = df[['Response Time (sec)', 'Customer Satisfaction Score', 'Chatbot Interactions']]\n",
        "y = df['Final Grade']\n",
        "\n",
        "# Train-Test Split (80% Train, 20% Test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Feature Scaling (Standardization)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train the Linear Regression Model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Define the Prediction Function\n",
        "def predict_final_grade(response_time, satisfaction_score, chatbot_interactions):\n",
        "    # Prepare the input data as a DataFrame\n",
        "    input_data = pd.DataFrame({\n",
        "        'Response Time (sec)': [response_time],\n",
        "        'Customer Satisfaction Score': [satisfaction_score],\n",
        "        'Chatbot Interactions': [chatbot_interactions]\n",
        "    })\n",
        "\n",
        "    # Scale the input data using the same scaler used for training\n",
        "    input_scaled = scaler.transform(input_data)\n",
        "\n",
        "    # Make the prediction using the trained model\n",
        "    predicted_grade = model.predict(input_scaled)\n",
        "\n",
        "    # Return the predicted final grade\n",
        "    return predicted_grade[0]\n",
        "\n",
        "# Example usage of the Prediction Function\n",
        "response_time = 50\n",
        "satisfaction_score = 7\n",
        "chatbot_interactions = 40\n",
        "\n",
        "predicted_grade = predict_final_grade(response_time, satisfaction_score, chatbot_interactions)\n",
        "\n",
        "print(f\"Predicted Final Grade: {predicted_grade:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F4WD11gsCvOF",
        "outputId": "7b6075a9-065b-4d14-f6c5-0df0ea81d1ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Final Grade: 84.98\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create the Gradio Interface"
      ],
      "metadata": {
        "id": "_-LwLwVYDPEe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Sample dataset: customer interactions data\n",
        "data = {\n",
        "    'Response Time (sec)': [34, 120, 60, 90, 45, 30, 100, 70],\n",
        "    'Customer Satisfaction Score': [7, 8, 5, 9, 6, 7, 8, 6],\n",
        "    'Chatbot Interactions': [15, 45, 30, 60, 50, 20, 80, 55],\n",
        "    'Final Grade': [85, 60, 70, 95, 80, 72, 90, 75]  # Target: Final Grade (score)\n",
        "}\n",
        "\n",
        "# Convert to DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Features (X) and Target (y)\n",
        "X = df[['Response Time (sec)', 'Customer Satisfaction Score', 'Chatbot Interactions']]\n",
        "y = df['Final Grade']\n",
        "\n",
        "# Train-Test Split (80% Train, 20% Test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Feature Scaling (Standardization)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train the Linear Regression Model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Define the Prediction Function\n",
        "def predict_final_grade(response_time, satisfaction_score, chatbot_interactions):\n",
        "    # Prepare the input data as a DataFrame\n",
        "    input_data = pd.DataFrame({\n",
        "        'Response Time (sec)': [response_time],\n",
        "        'Customer Satisfaction Score': [satisfaction_score],\n",
        "        'Chatbot Interactions': [chatbot_interactions]\n",
        "    })\n",
        "\n",
        "    # Scale the input data using the same scaler used for training\n",
        "    input_scaled = scaler.transform(input_data)\n",
        "\n",
        "    # Make the prediction using the trained model\n",
        "    predicted_grade = model.predict(input_scaled)\n",
        "\n",
        "    # Return the predicted final grade\n",
        "    return f\"Predicted Final Grade: {predicted_grade[0]:.2f}\"\n",
        "\n",
        "# Create Gradio Interface\n",
        "inputs = [\n",
        "    gr.Number(label=\"Response Time (sec)\", value=50, precision=0),\n",
        "    gr.Slider(minimum=1, maximum=10, label=\"Customer Satisfaction Score\", value=7),\n",
        "    gr.Number(label=\"Chatbot Interactions\", value=40, precision=0)\n",
        "]\n",
        "\n",
        "outputs = gr.Textbox()\n",
        "\n",
        "# Launch Gradio Interface\n",
        "gr.Interface(fn=predict_final_grade, inputs=inputs, outputs=outputs, live=True).launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "LxztU4l6DVcn",
        "outputId": "b7973f22-3705-4364-d704-ba445ae25109"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://6020560235070cfc8a.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://6020560235070cfc8a.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    }
  ]
}